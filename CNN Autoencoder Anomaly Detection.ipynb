{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@judewells/image-anomaly-detection-novelty-detection-using-convolutional-auto-encoders-in-keras-1c31321c10f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image, ImageChops\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6416 images belonging to 13 classes.\n",
      "Found 2138 images belonging to 13 classes.\n",
      "Found 468 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create generators for training, validation and testing\n",
    "# Generate data from the images in a folder, allows use of datasets that do not fit in main memory all at once\n",
    "# Image resizing is done by the generator so a folder with any sized-images can be used\n",
    "# The named directory must contain one or more subfolders, path should look like apples_train/apple_class1/img1.jpg...\n",
    "\n",
    "batch_size = 85\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'apples_train/',\n",
    "    target_size=(96, 96),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'apples_test/',\n",
    "    target_size=(96, 96),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "anomaly_generator = test_datagen.flow_from_directory(\n",
    "    'eggplant/',\n",
    "    target_size=(96, 96),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0115 13:31:24.991538 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0115 13:31:24.993489 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0115 13:31:24.996419 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0115 13:31:25.011088 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0115 13:31:25.047195 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0115 13:31:25.085278 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 3)           219       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 3)           84        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 6, 6, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 8)           224       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 96, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 96, 96, 3)         435       \n",
      "=================================================================\n",
      "Total params: 3,738\n",
      "Trainable params: 3,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the convolutional autoencoder model \n",
    "# input shape must be the same size as the images that will be fed into it by the generators\n",
    "# The output layer must be the same dimensions as the original image\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same',activation='relu', input_shape=(96, 96, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(4,4), padding='same')) # using pool_size (4,4) makes the layer 4x smaller in height and width\n",
    "\n",
    "model.add(Conv2D(8,(3, 3),activation='relu',  padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4), padding='same'))\n",
    "\n",
    "model.add(Conv2D(3,(3, 3),activation='relu',  padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "#-------------------------\n",
    "model.add(Conv2D(3,(3, 3),activation='relu',  padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(8,(3, 3),activation='relu',  padding='same'))\n",
    "model.add(UpSampling2D((4, 4)))\n",
    "\n",
    "model.add(Conv2D(16,(3, 3),activation='relu',  padding='same'))\n",
    "model.add(UpSampling2D((4, 4)))\n",
    "\n",
    "model.add(Conv2D(3,(3, 3), activation='sigmoid', padding='same'))\n",
    "#-------------------------\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SESA67051\\Documents\\GitHub\\keras_anomaly_detection\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0115 13:31:36.899344 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0115 13:31:36.904229 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "W0115 13:31:37.079021 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0115 13:31:37.190315 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0115 13:31:37.191292 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0115 13:31:38.166821 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0115 13:31:38.167797 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W0115 13:31:38.665815 14972 module_wrapper.py:139] From c:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}}]]\n\t [[loss/mul/_119]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b44ecabe16c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         callbacks=[es, save_best])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sesa67051\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}}]]\n\t [[loss/mul/_119]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1/convolution}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30) # Early stopping (stops training when validation doesn't improve for {patience} epochs)\n",
    "model_filepath = 'models/model1.keras'\n",
    "save_best = keras.callbacks.ModelCheckpoint(model_filepath, monitor='val_loss', save_best_only=True, mode='min') # Saves the best version of the model to disk (as measured on the validation data set)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000 // batch_size,\n",
    "        epochs=600,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1000 // batch_size,\n",
    "        shuffle = True,\n",
    "        callbacks=[es, save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = 'models/model1.keras'   #Bruno pour ne pas faire l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training continues after improvement stops for the number of epochs equivalent to the 'patience' hyper-parameter\n",
    "# To get back the model that performed best on the validation set we load the checkpointed model from disk:\n",
    "model = keras.models.load_model(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model by viewing a sample of original and reconstructed images\n",
    "data_list = []\n",
    "batch_index = 0\n",
    "while batch_index <= train_generator.batch_index:\n",
    "    data = train_generator.next()\n",
    "    data_list.append(data[0])\n",
    "    batch_index = batch_index + 1\n",
    "\n",
    "predicted = model.predict(data_list[0])\n",
    "no_of_samples = 6\n",
    "_, axs = plt.subplots(no_of_samples, 2, figsize=(5, 8))\n",
    "axs = axs.flatten()\n",
    "imgs = []\n",
    "for i in range(no_of_samples):\n",
    "    imgs.append(data_list[i][i])\n",
    "    imgs.append(predicted[i])\n",
    "for img, ax in zip(imgs, axs):\n",
    "    ax.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the difference the difference in error between the validation (normal) images and anomalous images to be as high as possible\n",
    "print(f\"Error on validation set:{model.evaluate_generator(validation_generator)}, error on anomaly set:{model.evaluate_generator(anomaly_generator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the encoded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build a replica of the first half of the auto-encoder (the encoder only)\n",
    "# This network takes a an image which is 96x96x3 and compresses it down to a 3x3x3 tensor\n",
    "encoder_replica = Sequential()\n",
    "encoder_replica.add(Conv2D(16, (3, 3), padding='same',activation='relu', input_shape=(96, 96, 3), weights=model.layers[0].get_weights()) )\n",
    "encoder_replica.add(MaxPooling2D(pool_size=(4,4), padding='same'))\n",
    "encoder_replica.add(Conv2D(8,(3, 3),activation='relu',  padding='same', weights=model.layers[2].get_weights()))\n",
    "encoder_replica.add(MaxPooling2D(pool_size=(4,4), padding='same'))\n",
    "encoder_replica.add(Conv2D(3,(3, 3),activation='relu',  padding='same', weights=model.layers[4].get_weights()))\n",
    "encoder_replica.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "encoder_replica.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating encoded (compressed versions of the training, validation and anomalous images) and getting their density\n",
    "# The SKLearn kernel density function only works with 1D arrays so we need to flatten the tensors created by the encoder\n",
    "encoded_images = encoder_replica.predict_generator(train_generator)\n",
    "encoded_images_flat = [np.reshape(img, (27)) for img in encoded_images]\n",
    "\n",
    "validation_encoded = encoder_replica.predict_generator(validation_generator)\n",
    "val_enc_flat = [np.reshape(img, (27)) for img in validation_encoded]\n",
    "\n",
    "anom_encoded = encoder_replica.predict_generator(anomaly_generator)\n",
    "anom_enc_flat = [np.reshape(img, (27)) for img in anom_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Density Estimation of the encoded vectors\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_flat)\n",
    "training_density_scores = kde.score_samples(encoded_images_flat) \n",
    "validation_density_scores = kde.score_samples(val_enc_flat)\n",
    "anomaly_density_scores = kde.score_samples(anom_enc_flat)\n",
    "\n",
    "# Plotting the density distributions of the training (normal), validation (normal) and anomalous images\n",
    "# Ideally we want to see high separation between the normal and anomalous classes\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title('Distribution of Density Scores')\n",
    "plt.hist(training_density_scores, 12, alpha=0.5, label='Training Normal')\n",
    "plt.hist(validation_density_scores, 12, alpha=0.5, label='Validation Normal')\n",
    "plt.hist(anomaly_density_scores, 12, alpha=0.5, label='Anomalies')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Density Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a function that will classify whether an unseen image is normal or an anomaly\n",
    "# Low density and high reconstruction error mean that the image is likely to be anomalous\n",
    "def check_anomaly(img_path):\n",
    "    density_threshold = 0 # This threshold was chosen based on looking at the distribution of the density scores of the normal class (validation set)\n",
    "    reconstruction_error_threshold = 0.04 # This threshold was chosen based on looking at the distribution of reconstruction errors of the normal class\n",
    "    img  = Image.open(img_path)\n",
    "    img = np.array(img.resize((96,96), Image.ANTIALIAS))\n",
    "    img = img / 255\n",
    "    encoded_img = encoder_replica.predict([[img]]) # Create a compressed version of the image using the encoder\n",
    "    encoded_img = [np.reshape(img, (27)) for img in encoded_img] # Flatten the compressed image\n",
    "    density = kde.score_samples(encoded_img)[0] # get a density score for the new image\n",
    "#     print(f'density: {density}')\n",
    "    reconstruction = model.predict([[img]])\n",
    "    reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)\n",
    "#     print(f'reconstruction_error: {reconstruction_error}')\n",
    "    if density < density_threshold or reconstruction_error > reconstruction_error_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what proportion of onion images are classified as anomalous\n",
    "onion_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('onions'):\n",
    "    for x in filenames:\n",
    "        if x.endswith(\".jpg\"):\n",
    "            onion_files.append(os.path.join(dirpath, x))\n",
    "\n",
    "onion_predictions = []\n",
    "for file in onion_files:\n",
    "    onion_predictions.append(check_anomaly(file))\n",
    "print(sum(onion_predictions)/len(onion_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what proportion of apples are classified as anomalous (we hope that this will be close to zero)\n",
    "apples_test = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('apples_test'):\n",
    "    for x in filenames:\n",
    "        if x.endswith(\".jpg\"):\n",
    "            apples_test.append(os.path.join(dirpath, x))\n",
    "\n",
    "apples_predictions = []\n",
    "for file in apples_test:\n",
    "    apples_predictions.append(check_anomaly(file))\n",
    "print(sum(apples_predictions)/len(apples_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what proportion of aubergines/eggplants get classed as anomalous.\n",
    "eggplant_test = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('eggplant'):\n",
    "    for x in filenames:\n",
    "        if x.endswith(\".jpg\"):\n",
    "            eggplant_test.append(os.path.join(dirpath, x))\n",
    "\n",
    "eggplant_predictions = []\n",
    "for file in eggplant_test:\n",
    "    eggplant_predictions.append(check_anomaly(file))\n",
    "print(sum(eggplant_predictions)/len(eggplant_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peppers_test = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('peppers'):\n",
    "    for x in filenames:\n",
    "        if x.endswith(\".jpg\"):\n",
    "            peppers_test.append(os.path.join(dirpath, x))\n",
    "\n",
    "peppers_predictions = []\n",
    "for file in peppers_test:\n",
    "    peppers_predictions.append(check_anomaly(file))\n",
    "print(sum(peppers_predictions)/len(peppers_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(peppers_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
